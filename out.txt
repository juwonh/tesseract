황보주원 업무일지 2024.8.5 

pytorch 기반 deep learning architecture 학습 
pytorche 연구 논문들에서 구현된 모델 및 알고리즘들이 아주잘제공됨. 

pytorch transformer 를 활용한 자연어 처리 알고리즘 구현 
tokenizer VocabularyS 숫자로 변환 
embedding 문장을 matrix2 만듬 
encoder/decoder 텍스트를 벡터로 / 벡터를 텍스트로 

Vision diffusion model VAE (Variational Autoencoder)s, GAN(Generative Adversarial 
Network) 구현 
사람 얼굴인지 아닌지 판별하기 위해 학습을 통해 사람 얼굴 모양의 특성을 추출함 

50 
50 0 50 

Ollama 
Ollama= 사용하여 메타 llamas 비롯한 수많은 opensource LLME 무료로 내 ㅠㅁ(ㄷ에서 실행할 수 
있음 기존 06ㄷ로는 가장 저사양 80억개 parameter (568) 모델만 돌릴 수 있음 품질의 차이가 있음 
적어도 줌사양 700억개 perameter (4068), 고사양 4000억개 parameter 모델이 되어야 
chatGPTO| 비슷해짐. 

RAG (Retrieval Augmented Generation) 
domain-specific 문서를 학습시킴으로써 작은 SLM 활용하여 문제의 해답을 추출해서 제공 가능 

Langchain 
LLM 모델은 openAl chatGPT. Anthropic Claude, Meta LLama google Gemma Mistral, Phi 등 
1년에 2번 정도 획기적인 update= 함. 새로운 모델이 출시될 때마다 성능은 좋아지고 비용은 
술어듬. 여러 시 플랫폼들의 APIS 골라쓸 수 있는 시대임. 
Langchaing 통하여 API [만0010라를 손쉽게 관리하며 일관적인 서비스를 Hag 수 있음 
모델 티ㅁ26-40008도 가능 